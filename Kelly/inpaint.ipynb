{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import convolve2d\n",
    "import scipy.misc\n",
    "import argparse\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "#possion blending \n",
    "\n",
    "# pre-process the mask array so that uint64 types from opencv.imread can be adapted\n",
    "def prepare_mask(mask):\n",
    "    if type(mask[0][0]) is np.ndarray:\n",
    "        result = np.ndarray((mask.shape[0], mask.shape[1]), dtype=np.uint8)\n",
    "        for i in range(mask.shape[0]):\n",
    "            for j in range(mask.shape[1]):\n",
    "                if sum(mask[i][j]) > 0:\n",
    "                    result[i][j] = 1\n",
    "                else:\n",
    "                    result[i][j] = 0\n",
    "        mask = result\n",
    "    return mask\n",
    "\n",
    "def blend(img_target, img_source, img_mask, offset=(0, 0)):\n",
    "    # compute regions to be blended\n",
    "    region_source = (\n",
    "            max(-offset[0], 0),\n",
    "            max(-offset[1], 0),\n",
    "            min(img_target.shape[0]-offset[0], img_source.shape[0]),\n",
    "            min(img_target.shape[1]-offset[1], img_source.shape[1]))\n",
    "    region_target = (\n",
    "            max(offset[0], 0),\n",
    "            max(offset[1], 0),\n",
    "            min(img_target.shape[0], img_source.shape[0]+offset[0]),\n",
    "            min(img_target.shape[1], img_source.shape[1]+offset[1]))\n",
    "    region_size = (region_source[2]-region_source[0], region_source[3]-region_source[1])\n",
    "\n",
    "    # clip and normalize mask image\n",
    "    img_mask = img_mask[region_source[0]:region_source[2], region_source[1]:region_source[3]]\n",
    "    img_mask = prepare_mask(img_mask)\n",
    "    img_mask[img_mask==0] = False\n",
    "    img_mask[img_mask!=False] = True\n",
    "\n",
    "    # create coefficient matrix\n",
    "    A = scipy.sparse.identity(np.prod(region_size), format='lil')\n",
    "    for y in range(region_size[0]):\n",
    "        for x in range(region_size[1]):\n",
    "            if img_mask[y,x]:\n",
    "                index = x+y*region_size[1]\n",
    "                A[index, index] = 4\n",
    "                if index+1 < np.prod(region_size):\n",
    "                    A[index, index+1] = -1\n",
    "                if index-1 >= 0:\n",
    "                    A[index, index-1] = -1\n",
    "                if index+region_size[1] < np.prod(region_size):\n",
    "                    A[index, index+region_size[1]] = -1\n",
    "                if index-region_size[1] >= 0:\n",
    "                    A[index, index-region_size[1]] = -1\n",
    "    A = A.tocsr()\n",
    "    \n",
    "    # create poisson matrix for b\n",
    "    P = pyamg.gallery.poisson(img_mask.shape)\n",
    "\n",
    "    # for each layer (ex. RGB)\n",
    "    for num_layer in range(img_target.shape[2]):\n",
    "        # get subimages\n",
    "        t = img_target[region_target[0]:region_target[2],region_target[1]:region_target[3],num_layer]\n",
    "        s = img_source[region_source[0]:region_source[2], region_source[1]:region_source[3],num_layer]\n",
    "        t = t.flatten()\n",
    "        s = s.flatten()\n",
    "\n",
    "        # create b\n",
    "        b = P * s\n",
    "        for y in range(region_size[0]):\n",
    "            for x in range(region_size[1]):\n",
    "                if not img_mask[y,x]:\n",
    "                    index = x+y*region_size[1]\n",
    "                    b[index] = t[index]\n",
    "\n",
    "        # solve Ax = b\n",
    "        x = pyamg.solve(A,b,verb=False,tol=1e-10)\n",
    "\n",
    "        # assign x to target image\n",
    "        x = np.reshape(x, region_size)\n",
    "        x[x>255] = 255\n",
    "        x[x<0] = 0\n",
    "        x = np.array(x, img_target.dtype)\n",
    "        img_target[region_target[0]:region_target[2],region_target[1]:region_target[3],num_layer] = x\n",
    "\n",
    "    return img_target\n",
    "\n",
    "\n",
    "def test():\n",
    "    img_mask = np.asarray(PIL.Image.open('./testimages/test1_mask.png'))\n",
    "    img_mask.flags.writeable = True\n",
    "    img_source = np.asarray(PIL.Image.open('./testimages/test1_src.png'))\n",
    "    img_source.flags.writeable = True\n",
    "    img_target = np.asarray(PIL.Image.open('./testimages/test1_target.png'))\n",
    "    img_target.flags.writeable = True\n",
    "    img_ret = blend(img_target, img_source, img_mask, offset=(40,-30))\n",
    "    img_ret = PIL.Image.fromarray(np.uint8(img_ret))\n",
    "    img_ret.save('./testimages/test1_ret.png')\n",
    "\n",
    "\n",
    "\n",
    "class ModelInpaint():\n",
    "    def __init__(self, modelfilename, iters, l, learning_rate, momentum,\n",
    "                 model_name='dcgan',\n",
    "                 gen_input='z:0', gen_output='Tanh:0', gen_loss='Mean_2:0',\n",
    "                 disc_input='real_images:0', disc_output='Sigmoid:0',\n",
    "                 z_dim=100, batch_size=64):\n",
    "        \"\"\"\n",
    "        Model for Semantic image inpainting.\n",
    "        Loads frozen weights of a GAN and create the graph according to the\n",
    "        loss function as described in paper\n",
    "        Arguments:\n",
    "            modelfilename - tensorflow .pb file with weights to be loaded\n",
    "            config - training parameters: lambda_p, nIter\n",
    "            gen_input - node name for generator input\n",
    "            gen_output - node name for generator output\n",
    "            disc_input - node name for discriminator input\n",
    "            disc_output - node name for discriminator output\n",
    "            z_dim - latent space dimension of GAN\n",
    "            batch_size - training batch size\n",
    "        \"\"\"\n",
    "\n",
    "      \n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.z_dim = z_dim\n",
    "#         self.graph, self.graph_def = ModelInpaint.loadpb(modelfilename,\n",
    "#                                                          model_name)\n",
    "\n",
    "        self.graph = ModelInpaint.restore_graph()\n",
    "\n",
    "        self.gi = self.graph.get_tensor_by_name(gen_input)\n",
    "        self.go = self.graph.get_tensor_by_name(gen_output)\n",
    "        self.gl = self.graph.get_tensor_by_name(gen_loss)\n",
    "        self.di = self.graph.get_tensor_by_name(disc_input)\n",
    "        self.do = self.graph.get_tensor_by_name(disc_output)\n",
    "        \n",
    "        #new edits \n",
    "        self.training = self.graph.get_tensor_by_name('inputs/is_training:0')\n",
    "\n",
    "        self.image_shape = self.go.shape[1:].as_list()\n",
    "\n",
    "        self.l = l\n",
    "        self.lr = learning_rate\n",
    "        self.iters = iters\n",
    "        self.momentum = momentum\n",
    "\n",
    "        self.sess = tf.Session(graph=self.graph)\n",
    "\n",
    "        self.init_z()\n",
    "\n",
    "    def init_z(self):\n",
    "        \"\"\"Initializes latent variable z\"\"\"\n",
    "        self.z = np.random.randn(self.batch_size, self.z_dim)\n",
    "\n",
    "    def sample(self, z=None):\n",
    "        \"\"\"GAN sampler. Useful for checking if the GAN was loaded correctly\"\"\"\n",
    "        if z is None:\n",
    "            z = self.z\n",
    "        #new edits \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        sample_out = self.sess.run(self.go, feed_dict={self.gi: z, self.training: False})\n",
    "        return sample_out\n",
    "\n",
    "    def preprocess(self, images, imask, useWeightedMask = True, nsize=7):\n",
    "        \"\"\"Default preprocessing pipeline\n",
    "        Prepare the data to be fed to the network. Weighted mask is computed\n",
    "        and images and masks are duplicated to fill the batch.\n",
    "        Arguments:\n",
    "            image - input image\n",
    "            mask - input mask\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        images = ModelInpaint.imtransform(images)\n",
    "        if useWeightedMask:\n",
    "            mask = ModelInpaint.createWeightedMask(imask, nsize)\n",
    "        else:\n",
    "            mask = imask\n",
    "        mask = ModelInpaint.create3ChannelMask(mask)\n",
    "        \n",
    "        bin_mask = ModelInpaint.binarizeMask(imask, dtype='uint8')\n",
    "        self.bin_mask = ModelInpaint.create3ChannelMask(bin_mask)\n",
    "\n",
    "        self.masks_data = np.repeat(mask[np.newaxis, :, :, :],\n",
    "                                    self.batch_size,\n",
    "                                    axis=0)\n",
    "\n",
    "        #Generate multiple candidates for completion if single image is given\n",
    "        if len(images.shape) is 3:\n",
    "            self.images_data = np.repeat(images[np.newaxis, :, :, :],\n",
    "                                         self.batch_size,\n",
    "                                         axis=0)\n",
    "        elif len(images.shape) is 4:\n",
    "            #Ensure batch is filled\n",
    "            num_images = images.shape[0]\n",
    "            self.images_data = np.repeat(images[np.newaxis, 0, :, :, :],\n",
    "                                         self.batch_size,\n",
    "                                         axis=0)\n",
    "            ncpy = min(num_images, self.batch_size)\n",
    "            self.images_data[:ncpy, :, :, :] = images[:ncpy, :, :, :].copy()\n",
    "\n",
    "    def postprocess(self, g_out, blend = True):\n",
    "        \"\"\"Default post processing pipeline\n",
    "        Applies poisson blending using binary mask. (default)\n",
    "        Arguments:\n",
    "            g_out - generator output\n",
    "            blend - Use poisson blending (True) or alpha blending (False)\n",
    "        \"\"\"\n",
    "        images_out = ModelInpaint.iminvtransform(g_out)\n",
    "        images_in = ModelInpaint.iminvtransform(self.images_data)\n",
    "\n",
    "        if blend:\n",
    "            for i in range(len(g_out)):\n",
    "                images_out[i] = ModelInpaint.poissonblending(\n",
    "                    images_in[i], images_out[i], self.bin_mask\n",
    "                )\n",
    "        else:\n",
    "            images_out = np.multiply(images_out, 1-self.masks_data) \\\n",
    "                         + np.multiply(images_in, self.masks_data)\n",
    "\n",
    "        return images_out\n",
    "\n",
    "    def build_inpaint_graph(self):\n",
    "        \"\"\"Builds the context and prior loss objective\"\"\"\n",
    "        with self.graph.as_default():\n",
    "            self.masks = tf.placeholder(tf.float32,\n",
    "                                        [None] + self.image_shape,\n",
    "                                        name='mask')\n",
    "            self.images = tf.placeholder(tf.float32,\n",
    "                                         [None] + self.image_shape,\n",
    "                                         name='images')\n",
    "            self.context_loss = tf.reduce_sum(\n",
    "                    tf.contrib.layers.flatten(\n",
    "                        tf.abs(tf.multiply(self.masks, self.go) -\n",
    "                               tf.multiply(self.masks, self.images))), 1\n",
    "                )\n",
    "\n",
    "#             self.perceptual_loss = self.gl\n",
    "            self.perceptual_loss = tf.cast(self.gl, tf.float32)\n",
    "#             print(self.perceptual_loss)\n",
    "#             print(self.l)\n",
    "            \n",
    "            self.inpaint_loss = self.context_loss + self.l*self.perceptual_loss\n",
    "            self.inpaint_grad = tf.gradients(self.inpaint_loss, self.gi)\n",
    "\n",
    "    def inpaint(self, image, mask, blend=True):\n",
    "        \"\"\"Perform inpainting with the given image and mask with the standard\n",
    "        pipeline as described in paper. To skip steps or try other pre/post\n",
    "        processing, the methods can be called seperately.\n",
    "        Arguments:\n",
    "            image - input 3 channel image\n",
    "            mask - input binary mask, single channel. Nonzeros values are \n",
    "                   treated as 1\n",
    "            blend - Flag to apply Poisson blending on output, Default = True\n",
    "        Returns:\n",
    "            post processed image (merged/blneded), raw generator output\n",
    "        \"\"\"\n",
    "        self.build_inpaint_graph()\n",
    "        self.preprocess(image, mask)\n",
    "\n",
    "        imout = self.backprop_to_input()\n",
    "\n",
    "        return self.postprocess(imout, blend), imout\n",
    "\n",
    "    def backprop_to_input(self, verbose=True):\n",
    "        \"\"\"Main worker function. To be called after all initilization is done.\n",
    "        Performs backpropagation to input using (accelerated) gradient descent\n",
    "        to obtain latent space representation of target image\n",
    "        Returns:\n",
    "            generator output image\n",
    "        \"\"\"\n",
    "        v = 0\n",
    "        for i in range(self.iters):\n",
    "            out_vars = [self.inpaint_loss, self.inpaint_grad, self.go]\n",
    "            in_dict = {self.masks: self.masks_data,\n",
    "                       self.gi: self.z,\n",
    "                       self.images: self.images_data}\n",
    "\n",
    "            loss, grad, imout = self.sess.run(out_vars, feed_dict=in_dict)\n",
    "\n",
    "            v_prev = np.copy(v)\n",
    "            v = self.momentum*v - self.lr*grad[0]\n",
    "            self.z += (-self.momentum * v_prev +\n",
    "                       (1 + self.momentum) * v)\n",
    "            self.z = np.clip(self.z, -1, 1)\n",
    "\n",
    "            if verbose:\n",
    "                print('Iteration {}: {}'.format(i, np.mean(loss)))\n",
    "\n",
    "        return imout\n",
    "\n",
    "    @staticmethod\n",
    "    def loadpb(filename, model_name='dcgan'):\n",
    "        \"\"\"Loads pretrained graph from ProtoBuf file\n",
    "        Arguments:\n",
    "            filename - path to ProtoBuf graph definition\n",
    "            model_name - prefix to assign to loaded graph node names\n",
    "        Returns:\n",
    "            graph, graph_def - as per Tensorflow definitions\n",
    "        \"\"\"\n",
    "        with tf.gfile.GFile(filename, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "\n",
    "        with tf.Graph().as_default() as graph:\n",
    "            tf.import_graph_def(graph_def,\n",
    "                                input_map=None,\n",
    "                                return_elements=None,\n",
    "                                op_dict=None,\n",
    "                                producer_op_list=None,\n",
    "                                name=model_name)\n",
    "\n",
    "        return graph, graph_def\n",
    "    \n",
    "    \n",
    "    def restore_graph():\n",
    "        with tf.Session() as sess:\n",
    "            loader = tf.train.import_meta_graph('../Cars/checkpoints/DCGAN.ckpt.meta')\n",
    "            loader.restore(sess, '../Cars/checkpoints/DCGAN.ckpt')\n",
    "            graph = tf.get_default_graph()\n",
    "#                 for op in graph.get_operations():\n",
    "#                     print(op.name)\n",
    "#         print('yes')\n",
    "#         with tf.Graph().as_default() as graph:\n",
    "#             tf.import_graph_def(graph_def,\n",
    "#                                 input_map=None,\n",
    "#                                 return_elements=None,\n",
    "#                                 op_dict=None,\n",
    "#                                 producer_op_list=None,\n",
    "#                                 name=model_name)\n",
    "        return graph\n",
    "\n",
    "    @staticmethod\n",
    "    def imtransform(img):\n",
    "        \"\"\"Helper: Rescale pixel value ranges to -1 and 1\"\"\"\n",
    "        return np.array(img) / 127.5-1\n",
    "\n",
    "    @staticmethod\n",
    "    def iminvtransform(img):\n",
    "        \"\"\"Helper: Rescale pixel value ranges to 0 and 1\"\"\"\n",
    "        return (np.array(img) + 1.0) / 2.0\n",
    "\n",
    "    @staticmethod\n",
    "    def poissonblending(img1, img2, mask):\n",
    "        \"\"\"Helper: interface to external poisson blending\"\"\"\n",
    "        return blending.blend(img1, img2, 1 - mask)\n",
    "\n",
    "    @staticmethod\n",
    "    def createWeightedMask(mask, nsize=7):\n",
    "        \"\"\"Takes binary weighted mask to create weighted mask as described in \n",
    "        paper.\n",
    "        Arguments:\n",
    "            mask - binary mask input. numpy float32 array\n",
    "            nsize - pixel neighbourhood size. default = 7\n",
    "        \"\"\"\n",
    "        ker = np.ones((nsize,nsize), dtype=np.float32)\n",
    "        ker = ker/np.sum(ker)\n",
    "        wmask = mask * convolve2d(mask, ker, mode='same', boundary='symm')\n",
    "        return wmask\n",
    "\n",
    "    @staticmethod\n",
    "    def binarizeMask(mask, dtype=np.float32):\n",
    "        \"\"\"Helper function, ensures mask is 0/1 or 0/255 and single channel\n",
    "        If dtype specified as float32 (default), output mask will be 0, 1\n",
    "        if required dtype is uint8, output mask will be 0, 255\n",
    "        \"\"\"\n",
    "        assert(np.dtype(dtype) == np.float32 or np.dtype(dtype) == np.uint8)\n",
    "        bmask = np.array(mask, dtype=np.float32)\n",
    "        bmask[bmask>0] = 1.0\n",
    "        bmask[bmask<=0] = 0\n",
    "        if dtype == np.uint8:\n",
    "            bmask = np.array(bmask*255, dtype=np.uint8)\n",
    "        return bmask\n",
    "    \n",
    "    @staticmethod\n",
    "    def create3ChannelMask(mask):\n",
    "        \"\"\"Helper function, repeats single channel mask to 3 channels\"\"\"\n",
    "        assert(len(mask.shape)==2)\n",
    "        return np.repeat(mask[:,:,np.newaxis], 3, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--model_file', type=str, help=\"Pretrained GAN model\")\n",
    "# parser.add_argument('--lr', type=float, default=0.01)\n",
    "# parser.add_argument('--momentum', type=float, default=0.9)\n",
    "# parser.add_argument('--nIter', type=int, default=1000)\n",
    "# parser.add_argument('--imgSize', type=int, default=64)\n",
    "# parser.add_argument('--batch_size', type=int, default=64)\n",
    "# parser.add_argument('--lambda_p', type=float, default=0.1)\n",
    "# parser.add_argument('--checkpointDir', type=str, default='checkpoint')\n",
    "# parser.add_argument('--outDir', type=str, default='completions')\n",
    "# parser.add_argument('--blend', action='store_true', default=False,\n",
    "#                     help=\"Blend predicted image to original image\")\n",
    "# parser.add_argument('--maskType', type=str,\n",
    "#                     choices=['random', 'center', 'left', 'file'],\n",
    "#                     default='center')\n",
    "# parser.add_argument('--maskFile', type=str,\n",
    "#                     default=None,\n",
    "#                     help='Input binary mask for file mask type')\n",
    "# parser.add_argument('--maskThresh', type=int,\n",
    "#                     default=128,\n",
    "#                     help='Threshold in case input mask is not binary')\n",
    "# parser.add_argument('--in_image', type=str, default=None,\n",
    "#                     help='Input Image (ignored if inDir is specified')\n",
    "# parser.add_argument('--inDir', type=str, default=None,\n",
    "#                     help='Path to input images')\n",
    "# parser.add_argument('--imgExt', type=str, default='png',\n",
    "#                     help='input images file extension')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "def loadimage(filename):\n",
    "    img = scipy.misc.imread(filename, mode='RGB').astype(np.float)\n",
    "    return img\n",
    "\n",
    "\n",
    "def saveimages(outimages, prefix='samples'):\n",
    "    numimages = len(outimages)\n",
    "\n",
    "    if not os.path.exists(args.outDir):\n",
    "        os.mkdir(args.outDir)\n",
    "\n",
    "    for i in range(numimages):\n",
    "        filename = '{}_{}.png'.format(prefix, i)\n",
    "        filename = os.path.join(args.outDir, filename)\n",
    "        scipy.misc.imsave(filename, outimages[i, :, :, :])\n",
    "\n",
    "\n",
    "def gen_mask(maskType):\n",
    "    \n",
    "    \n",
    "#     image_shape = [args.imgSize, args.imgSize]\n",
    "    image_shape = [64, 64]\n",
    "    if maskType == 'random':\n",
    "        fraction_masked = 0.2\n",
    "        mask = np.ones(image_shape)\n",
    "        mask[np.random.random(image_shape[:2]) < fraction_masked] = 0.0\n",
    "    elif maskType == 'center':\n",
    "        scale = 0.25\n",
    "        assert(scale <= 0.5)\n",
    "        mask = np.ones(image_shape)\n",
    "        sz = 64\n",
    "        l = int(64*scale)\n",
    "        u = int(64*(1.0-scale))\n",
    "        mask[l:u, l:u] = 0.0\n",
    "    elif maskType == 'left':\n",
    "        mask = np.ones(image_shape)\n",
    "        c = args.imgSize // 2\n",
    "        mask[:, :c] = 0.0\n",
    "#     elif maskType == 'file':\n",
    "#         mask = loadmask(args.maskfile, args.maskthresh)\n",
    "    else:\n",
    "        assert(False)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def loadmask(filename, thresh=128):\n",
    "    immask = scipy.misc.imread(filename, mode='L')\n",
    "    image_shape = [args.imgSize, args.imgSize]\n",
    "    mask = np.ones(image_shape)\n",
    "    mask[immask < 128] = 0\n",
    "    mask[immaks >= 128] = 1\n",
    "    return mask\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     m = ModelInpaint(args.model_file, args)\n",
    "\n",
    "#     # Generate some samples from the model as a test\n",
    "#     imout = m.sample()\n",
    "#     saveimages(imout)\n",
    "\n",
    "#     mask = gen_mask(args.maskType)\n",
    "#     if args.inDir is not None:\n",
    "#         imgfilenames = glob( args.inDir + '/*.' + args.imgExt )\n",
    "#         print('{} images found'.format(len(imgfilenames)))\n",
    "#         in_img = np.array([loadimage(f) for f in imgfilenames])\n",
    "#     elif args.in_image is not None:\n",
    "#         in_img = loadimage(args.in_image)\n",
    "#     else:\n",
    "#         print('Input image needs to be specified')\n",
    "#         exit(1)\n",
    "\n",
    "#     inpaint_out, g_out = m.inpaint(in_img, mask, args.blend)\n",
    "#     scipy.misc.imsave(os.path.join(args.outDir, 'mask.png'), mask)\n",
    "#     saveimages(g_out, 'gen')\n",
    "#     saveimages(inpaint_out, 'inpaint')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../Cars/checkpoints/DCGAN.ckpt\n"
     ]
    }
   ],
   "source": [
    "model = ModelInpaint(modelfilename = '', iters=1500, l =0.1, learning_rate=0.0001,\n",
    "                      momentum=0.02,\n",
    "                 model_name='dcgan',\n",
    "                 gen_input='inputs/z:0', gen_output='Generator/tanh_fake:0', gen_loss='Generator_loss:0',\n",
    "                 disc_input='inputs/real:0', disc_output='Discriminator/sigmoid_real:0',\n",
    "                 z_dim=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some samples from the model as a test\n",
    "imout = model.sample()\n",
    "#     saveimages(imout)\n",
    "\n",
    "#     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(2,parentdir) \n",
    "from model.image_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [cv2.normalize(i, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F).astype(np.uint8) for i in imout]\n",
    "img_col = ImageCollector(np.asarray(images))\n",
    "img_col.show(np.asarray(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.image_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from google.cloud import storage\n",
    "import io\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = storage.Client()\n",
    "bucket = client.get_bucket('inpainting-final-project')\n",
    "b1 = bucket.get_blob('images/Cars/cars_test/cars_test/00001.jpg')\n",
    "b2 = bucket.get_blob('images/Cars/cars_test/cars_test/00002.jpg')\n",
    "s1 = bucket.get_blob('images/Cars/cars_test/cars_test/00001.jpg').download_as_string()\n",
    "s2 = bucket.get_blob('images/Cars/cars_test/cars_test/00002.jpg').download_as_string()\n",
    "img1 = Image.open(io.BytesIO(s1))\n",
    "resized_img1 = resize(img1)\n",
    "img2 = Image.open(io.BytesIO(s2))\n",
    "resized_img2 = resize(img2)\n",
    "\n",
    "b1.download_to_filename('test_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = [] \n",
    "\n",
    "test_images.append(img1)\n",
    "test_images.append(img2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = gen_mask('center')\n",
    "\n",
    "# out_images, our_mask = center_square(np.asarray(test_images))\n",
    "\n",
    "#     if args.inDir is not None:\n",
    "#         imgfilenames = glob( args.inDir + '/*.' + args.imgExt )\n",
    "#         print('{} images found'.format(len(imgfilenames)))\n",
    "#         in_img = np.array([loadimage(f) for f in imgfilenames])\n",
    "#     elif args.in_image is not None:\n",
    "#         in_img = loadimage(args.in_image)\n",
    "#     else:\n",
    "#         print('Input image needs to be specified')\n",
    "#         exit(1)\n",
    "\n",
    "#     inpaint_out, g_out = m.inpaint(in_img, mask, args.blend)\n",
    "#     scipy.misc.imsave(os.path.join(args.outDir, 'mask.png'), mask)\n",
    "#     saveimages(g_out, 'gen')\n",
    "#     saveimages(inpaint_out, 'inpaint')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = scipy.misc.imread('test_1.jpg', mode='RGB').astype(np.float)\n",
    "img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = resize(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inpaint_out, g_out = model.inpaint(img, mask, blend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.perceptual_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.context_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
